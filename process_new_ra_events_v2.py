#!/usr/bin/env python3
import json
import hashlib
from datetime import datetime
from pathlib import Path

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åŸºæº–ã«ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š
PROJECT_DIR = Path(__file__).parent.resolve()
DATA_DIR = PROJECT_DIR / "data"

EXISTING_RA_URLS = {
    "https://ra.co/events/2157837",
    "https://ra.co/events/2183392",
    "https://ra.co/events/2232438",
    "https://ra.co/events/2235008",
    "https://ra.co/events/2237078",
    "https://ra.co/events/2243597",
    "https://ra.co/events/2257508",
    "https://ra.co/events/2258087",
    "https://ra.co/events/2267756",
    "https://ra.co/events/2271023",
    "https://ra.co/events/2271086",
    "https://ra.co/events/2271090",
    "https://ra.co/events/2271096",
    "https://ra.co/events/2271100",
    "https://ra.co/events/2271104",
    "https://ra.co/events/2271119",
    "https://ra.co/events/2271128",
    "https://ra.co/events/2272536",
    "https://ra.co/events/2275774",
    "https://ra.co/events/2275899",
}

def normalize_string(s):
    """æ–‡å­—åˆ—ã‚’æ­£è¦åŒ–ï¼ˆå°æ–‡å­—åŒ–ã€ç©ºç™½é™¤å»ã€ç‰¹æ®Šæ–‡å­—ã®çµ±ä¸€ï¼‰"""
    if not s:
        return ""
    # å°æ–‡å­—åŒ–
    s = s.lower().strip()
    # è¤‡æ•°ã®ç©ºç™½ã‚’1ã¤ã«
    s = ' '.join(s.split())
    # ã‚ˆãã‚ã‚‹è¡¨è¨˜ã‚†ã‚Œã‚’çµ±ä¸€
    s = s.replace('kitkatclub', 'kitkat club')
    s = s.replace('kit kat club', 'kitkat club')
    # ãƒã‚¤ãƒ•ãƒ³ã¨ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚’ç©ºç™½ã«
    s = s.replace('-', ' ').replace('_', ' ')
    # é€£ç¶šã™ã‚‹ç©ºç™½ã‚’1ã¤ã«
    s = ' '.join(s.split())
    return s

def normalize_title_for_matching(title):
    """ã‚¿ã‚¤ãƒˆãƒ«ã‚’ãƒãƒƒãƒãƒ³ã‚°ç”¨ã«æ­£è¦åŒ–ï¼ˆã‚ˆã‚Šç·©ã„ï¼‰"""
    normalized = normalize_string(title)
    
    # "with"ä»¥é™ã®ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã‚’é™¤å»ï¼ˆä¾‹: "ANTEA with Yanamaste, RUIZ..." -> "antea"ï¼‰
    if ' with ' in normalized:
        normalized = normalized.split(' with ')[0].strip()
    if ' w/ ' in normalized:
        normalized = normalized.split(' w/ ')[0].strip()
    if ' w ' in normalized:
        normalized = normalized.split(' w ')[0].strip()
    
    # "tour", "presents", "pres." ãªã©ã®ä¸€èˆ¬çš„ãªã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»
    suffixes = [' tour', ' presents', ' pres.', ' pres', ' feat.', ' feat', ' ft.', ' ft']
    for suffix in suffixes:
        if normalized.endswith(suffix):
            normalized = normalized[:-len(suffix)].strip()
    
    return normalized

def generate_event_hash(title, date, venue):
    """ã‚¤ãƒ™ãƒ³ãƒˆã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’ç”Ÿæˆï¼ˆå³å¯†ãªä¸€è‡´ç”¨ï¼‰"""
    key = f"{normalize_string(title)}_{normalize_string(date)}_{normalize_string(venue)}"
    return hashlib.md5(key.encode()).hexdigest()[:8]

def generate_loose_event_key(title, date, venue):
    """ç·©ã„ãƒãƒƒãƒãƒ³ã‚°ç”¨ã®ã‚­ãƒ¼ï¼ˆé¡ä¼¼ã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡ºç”¨ï¼‰"""
    normalized_title = normalize_title_for_matching(title)
    normalized_venue = normalize_string(venue)
    return f"{normalized_title}_{date}_{normalized_venue}"

def load_existing_events():
    """æ—¢å­˜ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ã€å³å¯†ãªãƒãƒƒã‚·ãƒ¥ã¨ç·©ã„ã‚­ãƒ¼ã®ä¸¡æ–¹ã‚’ä¿æŒ"""
    existing_events_by_hash = {}
    existing_events_by_loose_key = {}
    
    for json_file in DATA_DIR.glob("*.json"):
        if json_file.name in ["manifest.json", "1.json", "2.json", "3.json", "4.json"]:
            continue
            
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
                if isinstance(data, list):
                    events_list = data
                elif "events" in data:
                    events_list = data["events"]
                else:
                    continue
                
                for event in events_list:
                    event_name = event.get("title") or event.get("name", "")
                    event_date = event.get("date", "")
                    event_venue = event.get("venue", "")
                    event_url = event.get("url", "")
                    event_id = event.get("id", "")
                    
                    event_info = {
                        "id": event_id,
                        "url": event_url,
                        "name": event_name,
                        "date": event_date,
                        "venue": event_venue,
                        "source_file": json_file.name
                    }
                    
                    # å³å¯†ãªãƒãƒƒã‚·ãƒ¥ã§ä¿å­˜
                    event_hash = generate_event_hash(event_name, event_date, event_venue)
                    existing_events_by_hash[event_hash] = event_info
                    
                    # ç·©ã„ã‚­ãƒ¼ã§ã‚‚ä¿å­˜
                    loose_key = generate_loose_event_key(event_name, event_date, event_venue)
                    if loose_key not in existing_events_by_loose_key:
                        existing_events_by_loose_key[loose_key] = []
                    existing_events_by_loose_key[loose_key].append(event_info)
                    
        except Exception as e:
            print(f"Warning: Could not load {json_file.name}: {e}")
    
    return existing_events_by_hash, existing_events_by_loose_key

def convert_ra_to_standard_format(ra_event):
    event = ra_event.get("event", {})
    
    start_time = event.get("startTime", "")
    date = event.get("date", "")
    
    if start_time:
        dt = datetime.fromisoformat(start_time.replace('Z', '+00:00'))
        date_str = dt.strftime('%Y-%m-%d')
        time_str = dt.strftime('%H:%M')
    else:
        dt = datetime.fromisoformat(date.replace('Z', '+00:00'))
        date_str = dt.strftime('%Y-%m-%d')
        time_str = "23:00"
    
    artists = [artist.get("name", "") for artist in event.get("artists", [])]
    
    venue = event.get("venue", {})
    venue_name = venue.get("name", "")
    
    content_url = event.get("contentUrl", "")
    ra_url = f"https://ra.co{content_url}" if content_url else ""
    
    standard_event = {
        "id": "",
        "venue": venue_name,
        "date": date_str,
        "title": event.get("title", ""),
        "artists": artists,
        "startTime": time_str,
        "url": ra_url
    }
    
    return standard_event

def process_new_events():
    print("æ—¢å­˜ã‚¤ãƒ™ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­...")
    existing_by_hash, existing_by_loose_key = load_existing_events()
    print(f"æ—¢å­˜ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {len(existing_by_hash)}")
    print(f"ç·©ã„ã‚­ãƒ¼æ•°: {len(existing_by_loose_key)}")
    
    new_events = []
    skipped_events = []
    
    for i in range(1, 5):
        json_file = DATA_DIR / f"{i}.json"
        if not json_file.exists():
            print(f"  âš ï¸  {i}.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            continue
            
        print(f"\n{json_file.name} ã‚’å‡¦ç†ä¸­...")
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        event_listings = data.get("data", {}).get("eventListings", {}).get("data", [])
        
        for listing in event_listings:
            standard_event = convert_ra_to_standard_format(listing)
            
            # å³å¯†ãªãƒãƒƒã‚·ãƒ¥ã§ãƒã‚§ãƒƒã‚¯
            event_hash = generate_event_hash(
                standard_event["title"],
                standard_event["date"],
                standard_event["venue"]
            )
            
            # ç·©ã„ã‚­ãƒ¼ã§ãƒã‚§ãƒƒã‚¯
            loose_key = generate_loose_event_key(
                standard_event["title"],
                standard_event["date"],
                standard_event["venue"]
            )
            
            # ã¾ãšå³å¯†ãªãƒãƒƒã‚·ãƒ¥ã§ä¸€è‡´ã‚’ãƒã‚§ãƒƒã‚¯
            if event_hash in existing_by_hash:
                existing = existing_by_hash[event_hash]
                existing_url = existing.get("url", "")
                
                if existing_url and not existing_url.startswith("https://ra.co"):
                    print(f"  â­ï¸  ã‚¹ã‚­ãƒƒãƒ— (å³å¯†ä¸€è‡´): {standard_event['title']}")
                    print(f"      æ—¢å­˜: {existing['name']} (URL: {existing_url})")
                    skipped_events.append({
                        "ra_event": standard_event,
                        "existing_event": existing,
                        "reason": "exact_match_non_ra"
                    })
                    continue
                
                standard_event["id"] = existing["id"]
                print(f"  âœ“ æ—¢å­˜ (å³å¯†ä¸€è‡´): {standard_event['title']} (ID: {existing['id']})")
            
            # å³å¯†ä¸€è‡´ã—ãªã„å ´åˆã€ç·©ã„ã‚­ãƒ¼ã§ãƒã‚§ãƒƒã‚¯
            elif loose_key in existing_by_loose_key:
                candidates = existing_by_loose_key[loose_key]
                
                # éRa.co URLã®å€™è£œãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                non_ra_candidates = [c for c in candidates if c["url"] and not c["url"].startswith("https://ra.co")]
                
                if non_ra_candidates:
                    existing = non_ra_candidates[0]
                    print(f"  â­ï¸  ã‚¹ã‚­ãƒƒãƒ— (é¡ä¼¼ä¸€è‡´): {standard_event['title']}")
                    print(f"      æ—¢å­˜: {existing['name']} (URL: {existing['url']})")
                    skipped_events.append({
                        "ra_event": standard_event,
                        "existing_event": existing,
                        "reason": "similar_match_non_ra"
                    })
                    continue
                
                # Ra.co URLã®å€™è£œãŒã‚ã‚‹å ´åˆã¯æ—¢å­˜IDã‚’ä½¿ç”¨
                ra_candidates = [c for c in candidates if c["url"] and c["url"].startswith("https://ra.co")]
                if ra_candidates:
                    existing = ra_candidates[0]
                    standard_event["id"] = existing["id"]
                    print(f"  âœ“ æ—¢å­˜ (é¡ä¼¼ä¸€è‡´): {standard_event['title']} (ID: {existing['id']})")
                    print(f"      æ—¢å­˜: {existing['name']}")
            
            # æ–°è¦ã‚¤ãƒ™ãƒ³ãƒˆ
            if not standard_event["id"]:
                print(f"  + æ–°è¦: {standard_event['title']}")
            
            new_events.append(standard_event)
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä»Šæ—¥ã®æ—¥ä»˜ã§ä½œæˆ
    today = datetime.now().strftime("%Y-%m-%d")
    output_file = DATA_DIR / f"{today}-new-ra-events.json"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(new_events, f, ensure_ascii=False, indent=2)
    
    # ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆã®ãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›
    if skipped_events:
        report_file = DATA_DIR / f"{today}-skipped-events-report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(skipped_events, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ“„ ã‚¹ã‚­ãƒƒãƒ—ãƒ¬ãƒãƒ¼ãƒˆ: {report_file.name} ã« {len(skipped_events)} ä»¶ã®ã‚¹ã‚­ãƒƒãƒ—ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¨˜éŒ²")
    
    print(f"\nâœ… å‡¦ç†å®Œäº†: {len(new_events)} ã‚¤ãƒ™ãƒ³ãƒˆã‚’ {output_file.name} ã«å‡ºåŠ›ã—ã¾ã—ãŸ")
    print(f"   - æ—¢å­˜ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆIDã‚ã‚Šï¼‰: {sum(1 for e in new_events if e['id'])}")
    print(f"   - æ–°è¦ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆIDç©ºï¼‰: {sum(1 for e in new_events if not e['id'])}")
    print(f"   - ã‚¹ã‚­ãƒƒãƒ—: {len(skipped_events)} ã‚¤ãƒ™ãƒ³ãƒˆ")

if __name__ == "__main__":
    process_new_events()
